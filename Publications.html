<!DOCTYPE html>
<html  >
<head>
  <!-- Site made with Mobirise Website Builder v5.7.8, https://mobirise.com -->
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Mobirise v5.7.8, mobirise.com">
  <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
  <link rel="shortcut icon" href="assets/images/1.svg" type="image/x-icon">
  <meta name="description" content="">
  
  
  <title>Publications</title>
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap.min.css">
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap-grid.min.css">
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap-reboot.min.css">
  <link rel="stylesheet" href="assets/dropdown/css/style.css">
  <link rel="stylesheet" href="assets/socicon/css/styles.css">
  <link rel="stylesheet" href="assets/theme/css/style.css">
  <link rel="preload" href="https://fonts.googleapis.com/css?family=Jost:100,200,300,400,500,600,700,800,900,100i,200i,300i,400i,500i,600i,700i,800i,900i&display=swap" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Jost:100,200,300,400,500,600,700,800,900,100i,200i,300i,400i,500i,600i,700i,800i,900i&display=swap"></noscript>
  <link rel="preload" as="style" href="assets/mobirise/css/mbr-additional.css"><link rel="stylesheet" href="assets/mobirise/css/mbr-additional.css" type="text/css">

  
  
  
</head>
<body>
  
  <section data-bs-version="5.1" class="menu cid-s48OLK6784" once="menu" id="menu1-3n">
    
    <nav class="navbar navbar-dropdown navbar-fixed-top navbar-expand-lg">
        <div class="container-fluid">
            <div class="navbar-brand">
                <span class="navbar-logo">
                    <a href="http://www.baidu.com">
                        <img src="assets/images/1.svg" alt="Mobirise" style="height: 3.8rem;">
                    </a>
                </span>
                <span class="navbar-caption-wrap"><a class="navbar-caption text-white display-7" href="index.html#top">AIMIA-PKU</a></span>
            </div>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbarSupportedContent" data-bs-target="#navbarSupportedContent" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation">
                <div class="hamburger">
                    <span></span>
                    <span></span>
                    <span></span>
                    <span></span>
                </div>
            </button>
            <div class="collapse navbar-collapse" id="navbarSupportedContent">
                <ul class="navbar-nav nav-dropdown" data-app-modern-menu="true"><li class="nav-item"><a class="nav-link link text-primary display-4" href="index.html#content15-2w">Home</a></li><li class="nav-item"><a class="nav-link link text-primary display-4" href="index.html#features10-2n">Research</a></li><li class="nav-item"><a class="nav-link link text-primary display-4" href="index.html#content4-39">News</a></li><li class="nav-item"><a class="nav-link link text-primary display-4" href="Publications.html">Publications</a></li><li class="nav-item"><a class="nav-link link text-primary display-4" href="page3.html">Demo</a></li><li class="nav-item"><a class="nav-link link text-primary display-4" href="page6.html">Data</a></li><li class="nav-item"><a class="nav-link link text-primary display-4" href="index.html#content4-3b">Team</a></li><li class="nav-item"><a class="nav-link link text-primary display-4" href="index.html#content4-3d">Honors</a></li><li class="nav-item"><a class="nav-link link text-primary display-4" href="index.html#content4-3g">Openings</a></li></ul>
                
                <div class="navbar-buttons mbr-section-btn"><a class="btn btn-secondary display-4" href="index.html#content4-3e">
                        Contact us</a></div>
            </div>
        </div>
    </nav>

</section>

<section data-bs-version="5.1" class="content4 cid-ttomjRRmIf" id="content4-3q">
    
    
    <div class="container-fluid">
        <div class="row justify-content-center">
            <div class="title col-md-12 col-lg-11">
                <h3 class="mbr-section-title mbr-fonts-style align-center mb-4 display-2"><strong>Publications</strong></h3>
                
                
            </div>
        </div>
    </div>
</section>

<section data-bs-version="5.1" class="content4 cid-ttomE1qne1" id="content4-3s">
    
    
    <div class="container-fluid">
        <div class="row justify-content-center">
            <div class="title col-md-12 col-lg-11">
                <h3 class="mbr-section-title mbr-fonts-style align-center mb-4 display-2"><strong>Publications</strong></h3>
                
                
            </div>
        </div>
    </div>
</section>

<section data-bs-version="5.1" class="content6 cid-tzLp6CuHf8" id="content6-45">
    
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-12">
                <hr class="line">
                <p class="mbr-text align-center mbr-fonts-style my-4 display-1"><em>2023 Papers</em></p>
                <hr class="line">
            </div>
        </div>
    </div>
</section>

<section data-bs-version="5.1" class="content9 cid-tzLpbOBGCn" id="content9-46">
    

    <div class="container">
        <div class="row justify-content-center">
            <div class="counter-container col-md-12 col-lg-12">
                
                <div class="mbr-text mbr-fonts-style display-7">
                    <ol>
                        <li><span style="font-size: 1.3rem;">Hao Li, Jinfa Huang, Peng Jin, Guoli Song, Qi Wu and Jie Chen. "Weakly-Supervised 3D Spatial Reasoning for Text-based Visual Question Answering."&nbsp;IEEE Transactions on  Image Processing, 2023.</span></li><li><span style="font-size: 1.3rem;">Pengchong Qiao, Zhidan Wei, Yu Wang, Zhennan Wang, Guoli Song, Fan Xu, Xiangyang Ji, Chang Liu, Jie Chen. Fuzzy Positive Learning for Semi-supervised Semantic Segmentation[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. CVPR 2023. [<a href="assets/files/3.-Fuzzy-PositiveLearningforSemi-supervisedSemanticSegmentation.pdf" class="text-primary">Paper</a>]</span><br></li><li>Zesen Cheng, Pengchong Qiao, Kehan Li, Siheng Li, Pengxu Wei, Xiangyang Ji, Li Yuan, Chang Liu, Jie Chen. Out-of-Candidate Rectification for Weakly Supervised Semantic Segmentation[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. CVPR 2023. [<a href="assets/files/4.-Out-of-Candidate-RectificationforWeaklySupervisedSemanticSegmentation.pdf" class="text-primary">Paper</a>]</li><li>Peng Jin, JinFa Huang, Pengfei Xiong, Shangxuan Tian, Chang Liu, Xiangyang Ji, Li Yuan, Jie Chen. Video-Text as Game Players: Hierarchical Banzhaf Interaction for Cross-Modal Representation Learning[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. CVPR  2023. [<a href="assets/files/5.-Video-Text-asGamePlayers.pdf" class="text-primary">Paper</a>]</li><li>Kehan Li, Zhennan Wang, Zesen Cheng, Runyi Yu, Yian Zhao, Guoli Song, Chang Liu, Li Yuan, Jie Chen. ACSeg: Adaptive Conceptualization for Unsupervised Semantic Segmentation[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. CVPR 2023. [<a href="assets/files/6.-ACSeg-AdaptiveConceptualizationforUnsupervisedSemanticSegmentation.pdf" class="text-primary">Paper</a>]</li><li>Yu Wang, Pengchong Qiao, Guoli Song, Chang Liu, Xiawu Zheng, Jie Chen. Out-of-Distributed Semantic Pruning for Robust Semi-Supervised Learning.[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. CVPR 2023. [<a href="assets/files/7.-Out-of-Distributed-SemanticPruningforRobustSemi-SupervisedLearning.pdf" class="text-primary">Paper</a>]</li><li>Haoliang Zhao, Huizhou Zhou, Yongjun Zhang, Jie Chen, Yitong Yang, Yong Zhao. High-frequency Stereo Matching Network.[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. CVPR 2023.&nbsp;</li><li>Yan Y, Xiang G, Xie X, et al. <a href="https://ieeexplore.ieee.org/abstract/document/9858932" class="text-primary" target="_blank">Efficient Algorithm and Hardware Architecture for Rate Estimation in Mode Decision of AVS3</a>[C]//2022 IEEE International Conference on Multimedia and Expo (ICME). IEEE, 2022: 1-6.</li><li>Jucai Zhai, Pengcheng Zeng, Chihao Ma, Yong Zhao, Jie Chen，Learnable Blur Kernel for Single-Image Defocus Deblurring in the Wild，Association for the Advancement of Artificial Intelligence，AAAI, 2023.</li><li>Bin Fu , Hongliang He, Pengxu Wei , Jie Chen, Learning Task-Aligned Mask Query For Instance Segmentation, ICASSP 2023. [<a href="assets/files/2.-LEARNING-TASK-ALIGNEDMASKQUERYFORINSTANCESEGMENTATION.pdf" class="text-primary">Paper</a>]</li><li>Jifan Zhang, Zhe Wu, Xinfeng Zhang, Guoli Song, Yaowei Wang, Jie Chen, Recurrent Fine-Grained Self-Attention Network For Video Crowd Counting ICASSP 2023. [<a href="assets/files/1.-RECURRENT-FINE-GRAINEDSELF-ATTENTIONNETWORK.pdf" class="text-primary">Paper</a>]</li>
                    </ol>
                </div>
            </div>
        </div>
    </div>
</section>

<section data-bs-version="5.1" class="content6 cid-ttonnlrL9P" id="content6-3t">
    
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-12">
                <hr class="line">
                <p class="mbr-text align-center mbr-fonts-style my-4 display-1"><em>2022 Papers</em></p>
                <hr class="line">
            </div>
        </div>
    </div>
</section>

<section data-bs-version="5.1" class="features3 cid-ttomg9asFn" id="features3-3p">
    
    
    <div class="container">
        
        <div class="row mt-4">
            <div class="item features-image сol-12 col-md-6 col-lg-4 active">
                <div class="item-wrapper">
                    <div class="item-img">
                        <img src="assets/images/paper1-2-816x481.png" alt="" data-slide-to="0" data-bs-slide-to="0">
                    </div>
                    <div class="item-content">
                        <h5 class="item-title mbr-fonts-style display-7"><strong>Locality Guidance for Improving Vision&nbsp;</strong><strong>Transformers on Tiny Datasets (ECCV 2022)</strong></h5>
                        
                        <p class="mbr-text mbr-fonts-style mt-3 display-7">This paper proposes the locality guidance for improving the performance of VTs on tiny datasets.<br><strong>See here for<b> <a href="https://arxiv.org/pdf/2207.10026.pdf" class="text-primary" target="_blank" style=""><b>Paper&nbsp;and Code</b></a></b></strong>.</p>
                    </div>
                    
                </div>
            </div>
            
            <div class="item features-image сol-12 col-md-6 col-lg-4">
                <div class="item-wrapper">
                    <div class="item-img">
                        <img src="assets/images/paper2-2-2029x993.png" alt="" data-slide-to="1" data-bs-slide-to="1">
                    </div>
                    <div class="item-content">
                        <h5 class="item-title mbr-fonts-style display-7"><strong>Joint Learning of Object Graph And Relation Graph For Visual Question Answering (ICME 2022)</strong></h5>
                        
                        <p class="mbr-text mbr-fonts-style mt-3 display-7">This paper introduces<br>a novel Dual Message-passing enhanced Graph Neural Network.&nbsp;<br><strong>See here for</strong> <a href="https://arxiv.org/pdf/2205.04188.pdf" class="text-primary" target="_blank" style="font-weight: bold;"><strong>Paper and Code</strong></a>.<br></p>
                    </div>
                    
                </div>
            </div><div class="item features-image сol-12 col-md-6 col-lg-4">
                <div class="item-wrapper">
                    <div class="item-img">
                        <img src="assets/images/paper3-1-816x371.png" alt="" data-slide-to="2" data-bs-slide-to="2">
                    </div>
                    <div class="item-content">
                        <h5 class="item-title mbr-fonts-style display-7"><strong>Training-free Transformer Architecture Search (CVPR 2022)</strong></h5>
                        
                        <p class="mbr-text mbr-fonts-style mt-3 display-7">This paper, for the first time,&nbsp; investigates how to conduct TAS in a training-free manner and devise an effective trainingfree TAS scheme.<br><strong>See here for</strong> <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Training-Free_Transformer_Architecture_Search_CVPR_2022_paper.pdf" class="text-primary" target="_blank"><strong>Paper and Code</strong></a>.<br></p>
                    </div>
                    
                </div>
            </div>
        </div>
    </div>
</section>

<section data-bs-version="5.1" class="content9 cid-ttomksPB20" id="content9-3r">
    

    <div class="container">
        <div class="row justify-content-center">
            <div class="counter-container col-md-12 col-lg-12">
                
                <div class="mbr-text mbr-fonts-style display-7">
                    <ol>
                        <li>Wang Z, Li K, Yu R, et al. <a href="https://arxiv.org/pdf/2207.02625" class="text-primary" target="_blank">Difference in Euclidean Norm Can Cause Semantic Divergence in Batch Normalization</a>[J]. arXiv preprint arXiv:2207.02625, 2022.</li>
                        <li>Ren Q, Chen J. <a href="https://www.mdpi.com/2813-0324/3/1/8/htm" class="text-primary" target="_blank">Dual Complementary Prototype Learning for Few-Shot Segmentation</a>[C]//Computer Sciences &amp; Mathematics Forum. MDPI, 2022, 3(1): 8.</li>
                        <li>Zhang W, Wu Z, Zhang X, et al. <a href="https://ieeexplore.ieee.org/abstract/document/9945635" class="text-primary" target="_blank">Robust and Hierarchical Spatial Relation Analysis for Traffic Forecasting</a>[J]. IEEE Transactions on Intelligent Transportation Systems, 2022.</li><li>Wang L, Ning M, Lu D, et al. <a href="https://link.springer.com/chapter/10.1007/978-3-031-16452-1_54" class="text-primary" target="_blank">An Inclusive Task-Aware Framework for Radiology Report Generation</a>[C]//International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, Cham, 2022: 568-577.</li><li>Zhang C, Cheng Y, Wei P, et al.<a href="https://openaccess.thecvf.com/content/CVPR2022W/RoSe/papers/Zhang_CENet_Consolidation-and-Exploration_Network_for_Continuous_Domain_Adaptation_CVPRW_2022_paper.pdf" class="text-primary" target="_blank"> CENet: Consolidation-and-Exploration Network for Continuous Domain Adaptation</a>[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 3426-3432.</li><li>Jin P, Huang J, Liu F, et al. <a href="https://arxiv.org/pdf/2211.11427" class="text-primary" target="_blank">Expectation-Maximization Contrastive Learning for Compact Video-and-Language Representations</a>[J]. arXiv preprint arXiv:2211.11427, 2022.</li><li>Li K, Yu R, Wang Z, et al. <a href="https://arxiv.org/pdf/2207.10026" class="text-primary" target="_blank">Locality guidance for improving vision transformers on tiny datasets</a>[C]//European Conference on Computer Vision. Springer, Cham, 2022: 110-127.</li><li>Wang L, Ning M, Lu D, et al. <a href="https://link.springer.com/chapter/10.1007/978-3-031-16452-1_54" class="text-primary" target="_blank">An Inclusive Task-Aware Framework for Radiology Report Generation</a>[C]//International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, Cham, 2022: 568-577.</li><li>Yan Y, Xiang G, Xie X, et al. <a href="https://ieeexplore.ieee.org/abstract/document/9858932" class="text-primary" target="_blank">Efficient Algorithm and Hardware Architecture for Rate Estimation in Mode Decision of AVS3</a>[C]//2022 IEEE International Conference on Multimedia and Expo (ICME). IEEE, 2022: 1-6.</li><li>Li H, Li X, Karimi B, et al. <a href="https://arxiv.org/pdf/2205.04188" class="text-primary" target="_blank">Joint learning of object graph and relation graph for visual question answering</a>[J]. arXiv preprint arXiv:2205.04188, 2022.</li><li>Zhou Q, Sheng K, Zheng X, et al. <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zhou_Training-Free_Transformer_Architecture_Search_CVPR_2022_paper.pdf" class="text-primary" target="_blank">Training-free Transformer Architecture Search</a>[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 10894-10903.</li><li>Cheng M, Sun Y, Wang L, et al. <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_ViSTA_Vision_and_Scene_Text_Aggregation_for_Cross-Modal_Retrieval_CVPR_2022_paper.pdf" class="text-primary" target="_blank">ViSTA: Vision and Scene Text Aggregation for Cross-Modal Retrieval</a>[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 5184-5193.</li><li>Zhang Y, Lin M, Lin C W, et al. <a href="https://arxiv.org/pdf/2104.11883" class="text-primary" target="_blank">Carrying Out CNN Channel Pruning in a White Box</a>[J]. IEEE Transactions on Neural Networks and Learning Systems, 2022.</li>
                    </ol>
                </div>
            </div>
        </div>
    </div>
</section>

<section data-bs-version="5.1" class="video4 cid-ttxpjGXvNQ" id="video4-44">
    
    
    
    <div class="container">
        <div class="title-wrapper mb-5">
            <h4 class="mbr-section-title mbr-fonts-style mb-0 display-2"><strong>戈登贝尔（Gordon Bell）新冠特别奖</strong></h4>
        </div>
        <div class="row align-items-center">
            <div class="col-12 col-lg-6 video-block">
                <div class="video-wrapper"><iframe class="mbr-embedded-video" src="https://www.youtube.com/embed/lOLynZp07AM?rel=0&amp;amp;&amp;showinfo=0&amp;autoplay=0&amp;loop=0" width="1280" height="720" frameborder="0" allowfullscreen></iframe></div>
                <p class="mbr-description pt-2 mbr-fonts-style display-4">
                    Video Description</p>
            </div>
            <div class="col-12 col-lg">
                <div class="text-wrapper">
                    <h5 class="mbr-section-subtitle mbr-fonts-style mb-3 display-5"><strong>领先于病毒的进化——通过人工智能模拟预测未来高风险新冠病毒变异株</strong></h5>
                    <p class="mbr-text mbr-fonts-style display-7">&nbsp; 11月17日，美国计算机协会（ACM）公布2022年度戈登贝尔新冠特别奖评选结果。北京大学深圳研究生院信息工程学院与鹏城实验室、山东大学组成的联合研究团队在自行研发的鹏程·神农生物信息研究平台上完成的“<strong>领先于病毒的进化——通过人工智能模拟预测未来高风险新冠病毒变异株</strong>”研究项目成功入围2022年度“戈登贝尔新冠特别奖”，也是本次入围的<strong>唯一</strong>来自中国团队的项目。<br>&nbsp; 北大主要参与者是来自信息工程学院的田永鸿教授、<strong>陈杰副教授</strong>和<strong>博士研究生聂志伟</strong>和来自数学科学学院的杨超教授。<br><br>点击此处查看<a href="assets/files/_.pdf" class="text-primary" target="_blank"><strong>相关论文</strong></a>和<a href="assets/files/_PPT.pdf" class="text-primary" target="_blank"><strong>PPT</strong></a>。<br><br></p>
                </div>
            </div>
        </div>
    </div>
</section>

<section data-bs-version="5.1" class="content6 cid-ttorR5LlVL" id="content6-3w">
    
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-12">
                <hr class="line">
                <p class="mbr-text align-center mbr-fonts-style my-4 display-1"><em>2021 Papers</em> (top10 cited)</p>
                <hr class="line">
            </div>
        </div>
    </div>
</section>

<section data-bs-version="5.1" class="content9 cid-ttos1djEdn" id="content9-3x">
    

    <div class="container">
        <div class="row justify-content-center">
            <div class="counter-container col-md-12 col-lg-12">
                
                <div class="mbr-text mbr-fonts-style display-7">
                    <ol>
                        <li>Li C, Xie C, Zhang B, et al. <a href="https://arxiv.org/pdf/1804.08254" class="text-primary" target="_blank">Memory attention networks for skeleton-based action recognition</a>[J]. IEEE Transactions on Neural Networks and Learning Systems, 2021.</li><li>Zhang C, Cao M, Yang D, et al. <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_CoLA_Weakly-Supervised_Temporal_Action_Localization_With_Snippet_Contrastive_Learning_CVPR_2021_paper.pdf" class="text-primary" target="_blank">Cola: Weakly-supervised temporal action localization with snippet contrastive learning</a>[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021: 16010-16019.</li><li>Wu Q, Dai P, Chen J, et al. <a href="http://openaccess.thecvf.com/content/CVPR2021/papers/Wu_Discover_Cross-Modality_Nuances_for_Visible-Infrared_Person_Re-Identification_CVPR_2021_paper.pdf" class="text-primary" target="_blank">Discover cross-modality nuances for visible-infrared person re-identification</a>[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021: 4330-4339.</li><li>Wang S, Li C, Wang R, et al. <a href="https://www.nature.com/articles/s41467-021-26216-9" class="text-primary" target="_blank">Annotation-efficient deep learning for automatic medical image segmentation</a>[J]. Nature communications, 2021, 12(1): 1-13.</li><li>He H, Zhang C, Chen J, et al. <a href="https://www.frontiersin.org/articles/10.3389/fmolb.2021.614174/full" class="text-primary" target="_blank">A hybrid-attention nested UNet for nuclear segmentation in histopathological images</a>[J]. Frontiers in Molecular Biosciences, 2021, 8: 614174.</li><li>Zheng X, Ji R, Chen Y, et al. <a href="https://drive.google.com/file/d/1PVqmUxaU7DkbvX_z6OQ-mrkaAA9C5sJi/view" class="text-primary" target="_blank">MIGO-NAS: Towards fast and generalizable neural architecture search</a>[J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2021, 43(9): 2936-2952.</li><li>Wu J, Xu H, Zhang S, et al. <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8116317/?utm_source=Chromium&utm_medium=rss&utm_content=1ZK2-GOkRV8PscslB9T8PF1SkWt3FQ2qZAUU0Cql3OXEuE_s5v&ff=20210518220420&v=2.14.4" class="text-primary" target="_blank">Joint segmentation and detection of COVID-19 via a sequential region generation network</a>[J]. Pattern recognition, 2021, 118: 108006.</li><li>He H, Huang Z, Ding Y, et al. <a href="http://openaccess.thecvf.com/content/ICCV2021/papers/He_CDNet_Centripetal_Direction_Network_for_Nuclear_Instance_Segmentation_ICCV_2021_paper.pdf" class="text-primary" target="_blank">CDNet: Centripetal Direction Network for Nuclear Instance Segmentation</a>[C]//Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021: 4026-4035.</li><li>Cheng M, Kong Z, Song G, et al. <a href="https://link.springer.com/chapter/10.1007/978-3-030-87193-2_68" class="text-primary" target="_blank">Learnable Oriented-Derivative Network for Polyp Segmentation</a>[C]//International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, Cham, 2021: 720-730.</li><li>Ding Y, Han Z, Zhou Y, et al.<a href="https://ieeexplore.ieee.org/abstract/document/9389760/" class="text-primary" target="_blank"> Dynamic perception framework for fine-grained recognition</a>[J]. IEEE Transactions on Circuits and Systems for Video Technology, 2021, 32(3): 1353-1365.</li><li><strong>...<br>See <b><a href="https://scholar.google.fi/citations?user=ZAZFfwwAAAAJ&hl=en  " class="text-primary" target="_blank"><b>here</b></a> </b>for more information.</strong></li>
                    </ol>
                </div>
            </div>
        </div>
    </div>
</section>

<section data-bs-version="5.1" class="content6 cid-tzLqu7eZWb" id="content6-47">
    
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-12">
                <hr class="line">
                <p class="mbr-text align-center mbr-fonts-style my-4 display-1">Patents</p>
                <hr class="line">
            </div>
        </div>
    </div>
</section>

<section data-bs-version="5.1" class="content9 cid-tzLqKeqQUb" id="content9-48">
    

    <div class="container">
        <div class="row justify-content-center">
            <div class="counter-container col-md-12 col-lg-12">
                
                <div class="mbr-text mbr-fonts-style display-7">
                    <ol>
                        <li><span style="font-size: 1.3rem;">高志强，陈杰，乔鹏冲，田永鸿. 一种胸部CT图像病灶分割模型的训练方法及系统[P].申请号202110705914.8，2021年6月24日</span><br></li>
                        <li>黄锦发，陈杰，高志强，田永鸿 . 一种基于Transformer的CT报告生成方法[P].申请号202110795676.4，2021年7月14日</li><li>陈杰、田永鸿、高文、王中岐、王林. 一种基于任务感知的报告自动生成方法及装置[P].申请号202211156398.9，2022年9月22日 初审通过
</li><li>陈杰、田永鸿、高文、王中岐、王林. 利用自然语言模型自动生成结构化报告的方法及相关设备[P].申请号202211078506.5，2022年9月5日 初审通过
</li><li>田永鸿、杨文明、王天誉、陈杰. 一种药物-靶点交互作用预测方法、系统及终端设备[P].申请号202210632799.0，2022年6月7日
</li><li>王珊珊，黄纬键，郑海荣，陈杰，周晖晖，田永鸿. 基于人机交互的模型训练方法、装置、终端及存储介质[P].申请号202211222416.9，2022年10月8日
</li><li>王珊珊、吴若有、黄纬键、陈杰. 一种基于对抗样本的医学图像重建方法及相关装置[P]. 申请号202211425844.1，2022年11月16日
</li><li>陈杰、田永鸿、高文、黄显淞、孔子尚.一种基于多任务学习的图像清洁度评估方法及相关装置[P].申请号202211475103.4，2022年11月23日
</li><li>陈杰、田永鸿、高文、黄显淞、孔子尚.一种基于可学习方向导数的病灶边缘检测方法及相关装置[P].申请号202211475402.8，2022年11月23日
</li><li>陈杰、田永鸿、高文、王中岐、王书博.一种基于区域互补聚合的人群计数方法及相关装置[P].申请号202211384415.4，2022年11月7日
</li><li>高文，陈杰，田永鸿，施振辉、夏源. 基于图路径搜索和语义索引的医疗问答系统[P].申请号202211709241.4，2022年12月29日
</li><li>高文，陈杰，田永鸿，王兆玮.一种基于数据增强的肝脏CT肿瘤分割方法[P].申请号202211623471.9，2022年12月16日
</li><li>陈杰、田永鸿、高文、王中岐、任前. 基于注意力机制的小样本分割方法、装置、终端及介质[P].申请号202211569888.1，2022年12月8日
</li><li>陈杰，田永鸿，高文，黄显淞，黄钟毅.一种基于中心点的细胞核分割方法[P].申请号202211705880.3，2022年12月29日
</li><li>高文，陈杰，田永鸿，徐凡，耿睿哲.一种多尺度空间特征增强方法及装置[P].申请号202211569881.X，2022年12月8日
</li><li>田永鸿，陈杰，高文，徐凡，张弛.一种基于领域对关联的迁移学习方法及装置[P].申请号202211581443.5，2022年12月9日
</li><li>田永鸿，高文，陈杰，徐凡，耿睿哲.一种基于上下文特征融合的细胞核分割方法及相关设备[P].申请号202211580495.0，2022年12月9日
</li><li>田永鸿，陈杰，高文，徐凡，张弛.基于自适应参数隔离的迁移学习方法、装置、终端及介质[P].申请号202211579420.0，2022年12月8日
</li><li>陈杰、田永鸿、高文、黄显淞、徐凡、王中岐. 药物与蛋白质设计服务管理系统（软件著作权）.2022R11L1872673
</li><li>李代禧、陈杰、田永鸿、高文. 基于靶位结构和结合自由能的蛋白药物筛选软件（软件著作权）.2022R11L1988060
</li><li>李代禧、陈杰、田永鸿、高文.  基于Gromacs的分子模拟软件（软件著作权）.2022R11L1995041</li>
                    </ol>
                </div>
            </div>
        </div>
    </div>
</section><section class="display-7" style="padding: 0;align-items: center;justify-content: center;flex-wrap: wrap;    align-content: center;display: flex;position: relative;height: 4rem;"><a href="https://mobiri.se/" style="flex: 1 1;height: 4rem;position: absolute;width: 100%;z-index: 1;"><img alt=" Free Web Page  Building Software" style="height: 4rem;" src="data:image/gif;base64,R0lGODlhAQABAIAAAP///wAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw=="></a><p style="margin: 0;text-align: center;" class="display-7">Made with Mobirise &#8204;</p><a style="z-index:1" href="https://mobirise.com/website-design-software.html">Web Designing Software</a></section><script src="assets/bootstrap/js/bootstrap.bundle.min.js"></script>  <script src="assets/smoothscroll/smooth-scroll.js"></script>  <script src="assets/ytplayer/index.js"></script>  <script src="assets/dropdown/js/navbar-dropdown.js"></script>  <script src="assets/playervimeo/vimeo_player.js"></script>  <script src="assets/theme/js/script.js"></script>  
  
  
 <div id="scrollToTop" class="scrollToTop mbr-arrow-up"><a style="text-align: center;"><i class="mbr-arrow-up-icon mbr-arrow-up-icon-cm cm-icon cm-icon-smallarrow-up"></i></a></div>
  </body>
</html>